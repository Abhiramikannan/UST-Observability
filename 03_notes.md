05/08/25

link: https://app.pluralsight.com/library/courses/sre-monitoring-observability/table-of-contents

UNDERSTANDING PILLARS OF OBSERVABILITY:

<img width="1882" height="882" alt="image" src="https://github.com/user-attachments/assets/02692073-cc77-489f-ac0f-dce226d4ba49" />


Observability:  
      knowing internal states of a system from external outputs.
      collecting the information about whats happening inside the system.

collecting 3 informations i.e, 3 pillars of observability:

                1. metrices
                2. logs
                3. traces
                
some components working for that:
        1. collectors: 1 or more collectors to fetch the data
        2. 1 or more data stores
        3. various tools that make use of this data -> power ur dashboards, alerts,automation...



1. metrices: snapshot of set of numbers. Numeric data collected over time to measure the health or performance of systems.Used for monitoring performance, detecting anomalies, setting alerts.

 <img width="1869" height="920" alt="image" src="https://github.com/user-attachments/assets/35ec7c7a-97dc-4cf2-83c1-4c2f151f56ae" />


3. logs: Logs are text-based records automatically generated by applications and systems. They help developers and SREs understand what happened, when it happened, and where it happened.

<img width="1816" height="928" alt="image" src="https://github.com/user-attachments/assets/7088c1c8-9fca-4fb2-8536-0fab23372c58" />

   The image shows two types of logs:

                  Web Server (Apache) Log
                  
                  Application Log (CSV format)

       1. Apache Web Server Log

                sample log entry:
   
                             83.149.9.216 - - [08/May/2025:10:05:24 +0000] 
                            "GET /presentations/logstash-monitorama/images/1983_delorean_dmc-12-pic-38289.jpeg HTTP/1.1" 200 220562 
                            "http://semicomplete.com/presentations/logstash-monitorama/" 
                            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1)..."

                        | Part                           | Meaning                                             |
                        | ------------------------------ | --------------------------------------------------- |
                        | `83.149.9.216`                 | IP address of the user who accessed the server      |
                        | `[08/May/2025:10:05:24 +0000]` | **Timestamp** when the request was made             |
                        | `GET`                          | HTTP method used (in this case, it’s a GET request) |
                        | `/presentations/...jpeg`       | The file/resource the user requested                |
                        | `HTTP/1.1`                     | Protocol version                                    |
                        | `200`                          | HTTP status code (**200 = success**)                |
                        | `220562`                       | Size of the response (in bytes)                     |
                        | `"http://semicomplete.com/...` | Referrer (page that led to this request)            |
                        | `"Mozilla/5.0...`              | User-Agent (browser and OS of the requester)        |


      2. Application Log (from a CSV)

                sample log entry: 2025-05-08T12:28:15Z,35A2B2DB5232,ERROR,Fulfilment errored! Request ID: 30068808. Error message: document service unavailable.

              | Part                     | Meaning                                                |
              | ------------------------ | ------------------------------------------------------ |
              | `2025-05-08T12:28:15Z`   | **Timestamp** (ISO format — date + time in UTC)        |
              | `35A2B2DB5232`           | Unique ID (could be session ID, transaction ID, etc.)  |
              | `ERROR`                  | **Log level** — could be INFO, WARNING, ERROR, etc.    |
              | `Fulfilment errored!...` | **Message** — describes the actual issue that occurred |

         This log is showing an error during some order fulfilment, with a specific Request ID. The error message says that the "document service is unavailable", which likely means a backend service was down.

         Tools That Use These Logs:
         
                 Logstash / Elasticsearch / Kibana

                 Azure Monitor / AWS CloudWatch
                
                 Datadog, Splunk, Grafana Loki

         Logs help:

                Debug errors
                
                Audit what users did
                
                Track performance issues
                
                Trigger alerts when something goes wrong

                helps in alerting

4. traces:

 <img width="1919" height="1069" alt="image" src="https://github.com/user-attachments/assets/68f65c24-1f3d-494c-8923-d4c18107cd2a" />

        Get product service -> taking 0.38 seconds.
        GET /authz | 0.09s -> authorization service was called, taking 0.09 seconds.
        GET /p | 0.25s: Another call, possibly to a product service, taking 0.25 seconds.
        DB | 0.19s: A database query, taking 0.19 seconds.

   the distributed trace tells you the breakdown of all of those pieces of" (the rest is cut off). If a user complains that "the website is slow," distributed tracing helps you pinpoint exactly where the delay happened. Was it in the authorization service? The product service? The database?
   This allows engineers to quickly identify and fix performance bottlenecks or errors in complex, modern applications. It gives you a detailed "story" of each request's journey through your system.



  1. Published after the event: after the request.. traces publishes
  2. Service graph: Imagine a map of all your services and how they talk to each other. A trace shows you the actual paths requests take through this map, helping you visualize the dependencies and interactions between different parts of your system.
  3. Root cause analysis and alerting


REQUIREMENTS OF LOGS:

      collect -> proccess -> store
      
Logging Standards or What Makes Good Logs:

logs must:

            Write to known sink: This means logs must be sent to a designated, central place where they can be collected, stored, and analyzed (e.g., a logging system, a specific file path, or a cloud logging service). You shouldn't just leave them scattered on individual servers.
            eg: Send notes to one place: All notes must go to a central "notebook" so you don't lose them.
            
            Output JSON: Logs should be in JSON (JavaScript Object Notation) format. JSON is a structured, machine-readable format that makes it much easier for automated tools to parse, search, and analyze log data compared to plain text.
            
            Include log level: Every log entry must specify its "level" (e.g., INFO, WARN, ERROR, DEBUG). This indicates the severity or importance of the message, allowing you to filter and prioritize.
            
            Configurable level: You should be able to change the logging level (e.g., from INFO to DEBUG) without restarting the application. This is useful for troubleshooting, as you can temporarily get more detailed logs when diagnosing a problem.
   
logs should:
            
            Hot config reload: This refers to the ability to change the application's configuration (like logging levels, as mentioned above) without having to completely stop and restart the application. This minimizes downtime and operational overhead.
            
            Include context: Log messages should include relevant contextual information that helps understand why something happened. For example, if a user request failed, including the user ID, request ID, or transaction ID would be valuable for tracing the issue.

logs could:

      COULD (Nice to have, but not critical).Label the type of event: Give each note a clear "category" like "login successful" or "payment failed" so you can quickly find specific events


Logging stack:  "logging stack" refers to all the different components and processes that work together to collect, store, process, analyze, and visualize the logs generated by your applications and infrastructure.

GOOD LOGS,BAD LOGS:
Good logs are clear, structured, and useful for debugging, while bad logs are vague, inconsistent, or noisy and hard to understand.

KIBANA:
Kibana is a data visualization and dashboard tool used to explore and visualize data stored in Elasticsearch.


KEY REQUIREMENTS OF TRACING:

<img width="1298" height="657" alt="image" src="https://github.com/user-attachments/assets/39d50381-fe10-4efc-8d4b-8c00a5047664" />

user req -> goes to api service(entry point of app) ->The API or subsequent services interact with a database to retrieve or store data.->user interaction to the app

Fluentd: This is a popular open-source data collector. In this setup, Fluentd is likely collecting logs directly from the application containers. It processes these raw logs (e.g., parsing them into a structured format like JSON).

Elasticsearch: This is a powerful, distributed search and analytics engine. Fluentd sends the processed (and likely structured JSON) logs to Elasticsearch for storage and indexing. This makes the logs quickly searchable.

Kibana: This is a data visualization and exploration tool. It connects to Elasticsearch and allows users (like "Nina" in a different role, e.g., an SRE or developer) to query, filter, analyze, and visualize the log data stored in Elasticsearch. You can build dashboards, look for specific errors, or track trends.

 Fluentd collects the notes, Elasticsearch stores them neatly, and Kibana lets people search through and understand those notes to see what's happening inside the application.



 <img width="1371" height="745" alt="image" src="https://github.com/user-attachments/assets/c1b16f83-4ab9-4808-b829-08c4ba8a5007" />

 Q. how a single request is tracked.
       Span - GET (Multiple): These rectangles represent Spans. A Span is a single, identifiable unit of work within the overall request.The "START" circle means when that piece of work began.The "END" circle means when that piece of work finished.GET indicates an operation, like getting data from a service.
       Span - Load: This is another span, specifically for a loading operation, likely from a database.
       Parent Arrows: These show the hierarchy of the spans. A larger "parent" span (like the initial request) breaks down into smaller, dependent "child" spans (like calling another service or a database load).
       The Chain Icon: This reinforces the idea that these are all linked together as part of one complete trace.

Every trace have unique id.


DIFFERENEC B/W SPAN AND TRACE

TRACE: whole journey of users requests
SPAN: individual steps of that journey . eg: A service calling another service

TRACES- should,must,could 

<img width="1402" height="648" alt="image" src="https://github.com/user-attachments/assets/02c96b1e-fea2-4620-b3d0-fab5c3e49c95" />

Otel-Opentelemetry
Publish to OTel: Your application must send its trace data to an OpenTelemetry collector or endpoint. This ensures that the traces are centrally gathered and available for processing and analysis
.Include context: Traces should include relevant contextual information beyond just the basic operation. This could be things like a user_id, order_id, or customer_name. This extra data helps you filter traces and understand what specific business operations were happening during a trace.


IMPORTANT TERMS:

TRACING SUBSYSTEM
OpenTelemetry Collector (OTel Collector)
It collects logs, metrics, and traces from apps and sends them to tools like Grafana, Prometheus, or Tempo.

Tempo
It stores and shows traces – the full path of a request through different services.

 Grafana
It displays dashboards to monitor your system using data from Tempo (traces), Prometheus (metrics), Loki (logs), etc.

App → OpenTelemetry Collector → Tempo (traces), Prometheus (metrics), Loki (logs) → Grafana (visualize all)
