1. SPLUNK:
      like a search engine for all the machine generated data from ur computer,apps,devices..
      collects all the messy,unstructured data like login failed,user login and organizes it into a searchable format.
      it will make a label for similar data -> easier for search
      This process makes it easy to find and analyze specific events across all your systems, even if they're from different types of devices or applications.
      
2. What is a Splunk Instance?   
          A Splunk instance is a single installation of the Splunk software. 
          Think of it as a single copy of the program running on a computer.
          In a small setup, one instance can handle everything: taking in the data, organizing it, and letting you search it.
          In larger companies, they often use many Splunk instances that work together.
          Some are dedicated to collecting and organizing data (these are called indexers), and others are for running searches and showing dashboards (these are called search heads).
          This setup allows Splunk to handle massive amounts of data and searches at the same time without slowing down.
          
3. What does "Ingesting the Data" mean?
            Ingesting the data simply means getting the data into Splunk. It's the first step in the entire process
            Imagine Splunk as a giant storage locker for all your digital notes and logs. 
            Ingesting is the process of physically moving those notes from where they were created (like a web server or an app) and putting them inside that storage locker.
            Splunk can ingest data in different ways:
                        forwarders: like a delivery trucks put on all ur computers where they collect logs files as they are created and sent them to main splunk instance
                        API and NETWORK PORTS: 
                              NETWORK PORT : Its like a numbered door (eg: port 80)
                                             each computer have many network ports where the applications are listening to
                                             Imagine ur splunk instance is like a house
                                             To get the data inside the house(splunk instance), you need to open the door
                                             Each network port is like a different numbered door on the house
                              Splunk Listens at the Door:
                                             You can tell Splunk to stand at a specific door and wait for data to arrive. This is called "listening" on a port
                              HEC (HTTP Event Collector) is a Special Mailbox:
                                              Special Mailbox (HEC): HEC is like a special, secure mailbox you put outside your house (Splunk).
                                              Applications can directly drop their data into this mailbox using a specific key (a "token").
                                              This is a very clean and direct way to get data in, especially from modern web applications.
                                              the data from different application talk to eachother using API so using spluck you can create a input acalled hec and it can sent the data to the port where splunk is listening
                              Network Ports (TCP/UDP):
                                            some data can be tranferred through port not api
                                            sent log data over internet through certain ports
                                            the data  comes through the port of tcp and udp can be fetched..
                                            by setting up the port the splunk can listen on that port and grab the information
                              
                                                             

4. Can Splunk get data from all environments?
      yes. 
      from cloud(aws,google),computers
      It uses lightweight agents called forwarders to collect data from remote machines and forward it to a central Splunk instance.

5. SPLUNK USES A DATABASE-SPL?
           Splunk works with unstructured data (like logs), not the neat, organized tables of a traditional database. 
           You don't use a standard database query language like SQL. 
           Instead, you use Splunk's own flexible language, SPL (Search Processing Language), to find patterns and relationships within the data.
           This makes it a powerful search tool, not a traditional database.
           
6. Dashboard and panels in splunk?
              can save each specified search as 1 panel
              eg: ou run one specific search (for example, to count the number of failed logins), and that single count will be displayed in one panel on your dashboard.
              Each panel is dedicated to showing the result of its own specific search.

7. Transforming commands?
                  Transforming commands in Splunk change your raw data into a summarized view, like turning a long list of events into a simple chart or table.

8. BOOLEAN OPERATIONS IN SPLUNK?
            AND
            OR
            NOT
            ()
            ""
            \""
      AND is used to find events that contain all of the specified terms. This narrows your search. For example, login AND failed will only show events that have both the word "login" and the word "failed."
      OR is used to find events that contain at least one of the specified terms. This broadens your search. For example, error OR warning will show you any event that contains either "error" or "warning" (or both).
      NOT is used to exclude a specific term from your search results. For example, failed NOT password will show all events with the word "failed" but will remove any that also have the word "password." You can also use a minus sign         (-) as a shorthand for NOT, such as -password
      You can also use parentheses () to group terms and control how the Boolean logic is applied. For example, (login AND failed) OR error will find events that are either "login failed" or just the word "error."

9. Splunk search querry?
            index=network sourcetype=cisco_wsa_squid usage=Violation 
            | stats count(usage) as Visits by cs_username 
            | search Visits > 1

      | -> passes the outcome to the next
      stats count(usage) as Visits: This is a transforming command. It tells Splunk to count the number of times usage appears. It renames the count to a new field called Visits.
      search Visits > 1: This tells Splunk to show only the results where the new field Visits is greater than 1.

10. KNOWLEDGE OBJECTS?
             knowledge objects are things you create and save so Splunk can use them to better understand your data. They are the rules and definitions you build to make your data smarter.
             eg: When you create a search command and save it to use again later, that is a type of knowledge object called a Saved Search or Report.
                  It's a way to save your work so you don't have to rebuild the search every time, making it much easier and faster for you and others to get the same results.
            lookup is a knowledge object -> Adds extra information to your data based on a separate file you provided.
            Report is a knowledge object-> Re-runs the same search every time.

11. 3 ROLES ?
            ADMIN
            POWER
            USER

12. KNOWLEDGE OBJECTS ARE GROUPED INTO 5 CATEGORIES?
            Data Classification, -> classifying data into diff categories(tags to group similar events)
            Data Normalization,-> This is the process of cleaning and standardizing your data. eg: making sure all the dates are in the same format 
            Data Enrichment, and -> This step adds new, valuable information to your existing data. For instance, if your data has an IP address, you can "enrich" it by adding the city and country that IP address is from.
                                    This is often done using a lookup table
            Data Interpretation -> This is the final step where you look at the cleaned, enriched data to find meaningful insights, like trends or patterns. This is where you might create charts or reports to visualize your findings.
                                    Data Interpretation is done by creating Reports and Dashboards which use your classified, normalized, and enriched data to find insights.

13. can we add the report as panels in the dashboard in splunk?
            yes
            When you save a search as a report, it becomes a knowledge object that you can reuse. 
            One of the most common ways to reuse a report is to add it as a panel on a dashboard. 
            This allows you to display the results of that report alongside other information, providing a comprehensive, high-level view of your data in a single place.

14. can also edit the drill down in each panel..why it is used?
            detailed view of information

15. what is dashboard studio?
            Dashboard Studio is a modern dashboard-building environment in Splunk.
            easy to customize ur dashboard.
            
16. By default, who is able to view a saved report?

                  Any user with the viewreports capability
                  
                  The user who created it -> CORRECT
                  
                  The user who created it or any user with an admin role
                  
                  Any user with a power or admin role
17. What is the most efficient way to limit search results returned?

                  host
                  
                  time
                  
                  indeX
                  
                  source

18. search will active upto  10 mins

19. DEFAULT ROLE OF SPLUNK ENTERPRICES:
            USER
            POWER
            ADMIN

20. Which search mode behaves differently depending on the type of search being run?

                  Variable
                  
                  Smart 
                  
                  Verbose
                  
                  Fast
21. By default, which of the following roles are required to share knowledge objects?

                  Admin
                  
                  Power
                  
                  User
                  
                  Manager

22. Which of the following searches will return results containing the terms failed, password, or failed password?

                  failed OR password OR "failed password"
                  
                  failed OR password -> CORRECT
                  
                  failed password OR "failed password"
                  
                  fail*

23. Which Splunk infrastructure component stores ingested data?

      Index 
      
      Data models
      
      Dashboards
      
      Datasets

24. Which command can be used to further filter results in a search?

      search 
      
      subset
      
      subsearch
      
      filter

25. When a search is run, in what order are events returned?

            Reverse chronological order 
            
            Alphanumeric order
            
            Chronological order
            
            Reverse alphanumeric order

26. Which character is used in a search before a command?

            A quotation mark (")
            
            A backtick (`)
            
            A tilde (~)
            
            A pipe (|) 

27. What determines the timestamp shown on returned events in a search?

            Timestamps are displayed in epoch time
            
            The time zone where the event originated
            
            The time zone defined in user settings 
            
            Timestamps are displayed in Greenwich Mean Time



1/9/25
-------------------------------------------
USING FIELDS:
-------------------------------------
sourcetype=linux_search  -> returns only that events.(values)
field names are case sensitive,values are not

FIELD OPERATORS:
      =
      != 
      These are used in numerical and strings

      >
      <
      >=
      <= 
      these are used with numericals.

fields can added into search by clicking on the value in the fields window
can also use boolean in field value pair

eg:
index=security sourcetype=linux_secure action=failure NOT (host="mail*" OR host=www1)

index=security sourcetype=linux_secure action=failure: This part finds all events from the security index that are Linux security logs and have a "failure" action.

NOT (host="mail*" OR host=www1): This is a Boolean filter. It excludes any of the previous results where the host name either starts with "mail" (the asterisk is a wildcard) or is exactly "www1."

------------------------------------
The Difference between != and NOT:
----------------------------------------------------
            != status should be there and check condition
            Not: if status not there also it will return all the events after excluding status=200

      Imagine you have three events:

      status=200 user=john
      status=404 user=jane
      user=mary (no status field)

Search for status!=200: This would return only event #2 (status=404) because event #1 is a match and event #3 doesn't even have a status field to compare.

Search for NOT status=200: This would return events #2 and #3. It excludes event #1 because it has status=200, but includes event #3 because its status field is not 200 (it's null or non-existent).
---------------------------------------------
OR:
--------------------------------------------
             index=web (status=500 OR status=503 OR status=505)
                  tells splunk to look only in the index=web first
                  then go to paranthesis to group the condition -> status is either 500 or 503 or 505

-----------------------------------------------
IN:
----------------------------------------------
      index=web status IN ("500", "503", "505")
            shortcut for a series of OR operator

-----------------------------------------------------

PLACE FIELDS COMMAND BEFORE STATS:
----------------------------------------
index=web status IN ("500", "503", "505")
| fields status
| stats count by status
      
      placing the fields command before the stats command is a best practice for search performance.
      The fields command is a search filter. It tells Splunk to keep only the fields you specify.
      The stats command is a powerful transforming command in Splunk. It's used to calculate statistics on your search results, like counts, averages, sums, and totals.


also can give + to include the field and - to exclude the field 

      index=web status IN ("500", "503", "505")
      | fields +status
      | stats count by status

------------------------------------------------
RENAME:
      index=web status IN ("500", "503", "505")
      | fields status
      | stats count by status
      | rename status as "HTTP Status", count as "Number of Events"

            it changes the column name in the final tables.
            status will be HTTP Status and Count will be Number of events.
-------------------------------------------------------------------------

FIELDS IN SEARCH RESULTS:
      When Splunk ingests data, it automatically extracts a few key pieces of information from each event. These pieces are called default fields.
      These fields always include the source, sourcetype, and host. Splunk also identifies and extracts the timestamp of the event, which it stores as the _time field.
      This process happens automatically as soon as the data comes into Splunk, so you can immediately begin searching and filtering using these fields.

      host
      source
      sourcetype
      time
      raw

event: text ..like logs (user logged,A file being saved.)

            --------------------------------------------------
      1. EVAL:
            The eval command is a powerful command that creates a new field in your search results by evaluating an expression. You can use eval to perform calculations, convert data types, or manipulate field values.

index=network sourcetype=cisco_wsa_squid
| stats sum(sc_bytes) as Bytes by usage
| eval bandwidth = Bytes/1024/1024

      
