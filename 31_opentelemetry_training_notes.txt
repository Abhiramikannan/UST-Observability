1. CNCF:
    The Cloud Native Computing Foundation (CNCF) is part of the Linux Foundation and supports cloud native computing. 
    It helps developers build and run applications using containers and microservices.
    CNCF hosts popular open-source projects like Kubernetes, Prometheus, and Envoy, bringing together developers and companies to collaborate.

WHY DO WE NEED OPENTELEMETRY
-------------------------------------------
2. Observability: 
      Knowing internal parts of system using external outputs.

3. example of observability become crucial:
        diff computers working together to perform tasks as if they were a single system.
        These systems are widely used in applications like cloud computing, where different parts of an application run on different servers to share resources and balance the workload.
        Because of the complexity of distributed systems, it can be challenging to understand what's happening inside each component at any given time. 
        This is where observability becomes crucial.

To understand a distributed system, we model it using three parts:

    Workload: The tasks or transactions the system performs.
    Software structure: Components like load balancers, services, pods, and containers.
    Physical machines: Hardware resources such as CPU, memory, storage, and network.

Workload & Resource Analysis

    Developers focus on workloads (apps and requests).
    Operations teams focus on resources (hardware and performance).
    To fully understand the system, combine both views.
    Use logs, metrics, and traces to capture and analyze system behavior.


4. logs:
    A record of events that happen in a system.
    Log entry: Has a timestamp (when it happened) and a message (what happened).
    No single standard format — logs differ between software (e.g., web server vs. kernel).

5. Metrices:
    Metrics give a high-level view of system performance and health.
    Metrics help us track changes over time using graphs and dashboards.
    Four common types of metrics:
                Counters – Keep increasing (e.g., number of requests).
                Gauges – Go up or down (e.g., CPU or memory usage).
                Histograms – Measure distributions (e.g., request durations).
                Summaries – Show calculated stats like averages or percentiles.

6. Traces:
        Distributed System Architecture 
        
        As systems became larger and more complex, traditional logs were not enough to debug problems.
        In a distributed system, it’s hard to trace how one request moves through many services.
        On a single machine, we can use stack traces to find errors, but this doesn’t work across multiple systems.
        Debugging often required manual work (like matching timestamps) or deep system knowledge.
        To solve this, Google created Dapper, introducing distributed tracing — a method to track a request’s path across all services in a system.

7. 3 pillars of observability?
        metrices
        logs
        traces

8. Telemetry:
        collecting and transmitting data from remote or distributed systems to monitor, track performance of those systems.
        When we collect telemetry data (logs, metrics, and traces), we don’t just collect it — we also need to analyze it to find useful insights
        analyzation - depends on type of telemetry data

9. Vertical Integration?
        The telemetry data (logs,metrices, traces) can be handled differetly.
        logs = search text(find errors contains "timeout")
        metrics= analyse trends over time(e.g., average CPU use in the past 24 hours).
        Traces → You want to visualize a request flow (e.g., see how long each part of a user request took).
        So they need diff data storage, optimization methods, Querry tools.
    one tool that does the full job for a specific kind of telemetry.This is called Vertical Integration.
    Vendors (like Datadog, New Relic, or Grafana) often focus on one type of data at a time.

10.What does “siloed telemetry” mean?
        telemetry = collect data to understand how system behaves.
        siloed = each type of data (logs, metrics, traces) is separate, stored in different tools, and not connected.
    eg: metrices in prometheous, Logs in elasticsearch , traces in jaeger wont talk to eachother automatically.

    This cause an problem:
        when somethg is happening wrong
            u see metric alert - high latency. You search for related metrices maybe cpu, memory. Also move to logging system to find logs.
            logs don’t have trace IDs or context, so you can’t easily tell which logs are linked to the metric spike.
            You can see th whole story of what happened.
Issue:
    lack of corelation.  Hard to link data across systems.
    miss shared metadata (like trace_id or span_id) that would allow you to connect related events.
    This creates fragmented views — you see bits and pieces, but not the full picture of what the system did.
    OpenTelemetry was created to fix this fragmentation.

11. How Opentele helps to fix this fragmentation of telemetric data as compared from traditional approach?
            OpenTelemetry solves this by standardizing how telemetry is collected and by adding shared context (trace IDs, span IDs) so logs, metrics, and
            traces are connected.
            This gives a complete, end-to-end view of system behavior, making debugging faster and easier.
        
